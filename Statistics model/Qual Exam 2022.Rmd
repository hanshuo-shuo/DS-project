---
title: 'Qual Exam 2022: 350 & 353'
date: ''
author: 'Daihe Sui'
output:
  pdf_document: default
  html_document: default
urlcolor: blue
linkcolor: red
---

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(ggthemes)
library(pscl)
library(MASS)
library(lmtest)
library(sandwich)
library(boot)
library(glmnet)
library(splines)
data <- read_csv("SSOCS(2017-2018)Data.csv")
```

# An Overview of the Problem

In the United States, gun violence in K-12 schools has grown rapidly over the past two decades. For example, the mass shooting at Uvalde Elementary in Texas (2022) received a large degree of media attention. While the scale of this event was extreme, however, gun violence of smaller scales is more [common](https://news.google.com/search?q=gun%20school&hl=en-US&gl=US&ceid=US%3Aen) .

As gun violence increases, researchers and policymakers continue to search for solutions. These include ideas like increasing monitoring of social and mental health of students, using metal detectors, stationing police in schools, among others. This question - What can we do to reduce gun violence? - provides the background for this exam.

## The SSOCS Data

"The School Survey on Crime and Safety (SSOCS) — a nationally representative survey of U.S. K–12 public schools — is managed by the National Center for Education Statistics (NCES), an agency within the U.S. Department of Education’s Institute of Education Sciences. SSOCS collects detailed information from public schools on the incidence, frequency, seriousness, and nature of violence affecting students and school personnel. SSOCS also collects information on the programs, practices, and policies that schools have in place to prevent and reduce crime. Data from this collection can be used to examine the relationship between school characteristics and violent crimes in regular public primary, middle, high, and combined schools."

All of the information that you need to understand this data is provided. This includes:

 * `SSOCS(2017-2018)Data.csv` : The data
 * `ssocs codebook.pdf` : The code book

Notice that in the code book, the `Appendix A` includes the actual survey and that `Appendix B` includes a list of all the variable names and definitions. Further information on the creation of composite variables (those ending in "18") can be found in `Chapter 5`.



(Throughout, pay particular attention to data with values of "-1". These are purposeful skips and in many (but not all) cases may need to be re-coded to "0".)

## This Exam 

The purpose of this exam is to test your ability to put to use all that you have learned in STAT 350 and 353 in the context of real data, with a real question. This involves combining your understanding of regression concepts and theory with the implementation of these in code and clear interpretation to a lay audience. Be sure to convey what the results tell you, what assumptions they require, and any limitations in your results. 

For this exam, we will focus in particular on two outcomes:

  - `INCID18` : total incidents of any crime
  - `DISFIRE18` : total use of firearm or explosive

To simply the analysis, you can assume  the schools as a simple random sample, and ignore the sampling weights / jackknife replicates.
  
**Finally, a strong exam is one that is judicious in what is presented (you can put materials in an Appendix), that explains the decisions and assumptions that were made and why, that explains the how the results should be interpreted, and that is clear in any limitations.**


# Part I. Testing Hypotheses

As stated above, researchers and policymakers have hypothesized and enacted a variety of policies meant to reduce crimes and gun violence in schools. In particular, they often argue that schools should include *security guards* in order to reduce crime and gun violence.

For this part, answer the following questions:

1. After exploring the two outcomes (INCID18 and DISFIRE18) determine what type of regression model is appropriate for each (e.g., OLS). Explain your choice.

Let's first inspect these two outcome variables.

```{r hypothesis1}
## INCID18
table(data$INCID18)
ggplot(data = data, aes(x = INCID18)) + 
  geom_histogram(aes(y = ..density..)) +
  geom_density() +
  theme_economist()
```

We can see that `INCID18` is count data. We thus can think of using models for count data, such as Poisson regression and negative binomial regression. We will try using different models for our analysis later.

```{r}
## DISFIRE18
table(data$DISFIRE18)
```

As is mentioned in the problem sheet, we should first recode those -1s as 0.

```{r}
data[data$DISFIRE18 == -1, ]$DISFIRE18 <- 0
table(data$DISFIRE18)
```

We notice that `DISFIRE18` is also count data. However, there are a disproportionately large number of 0s in our dataset. We may probably need to use zero-inflated Poisson regression or hurdle model. Also notice there is an outlier -- one outcome is 81 which is far greater than other observations. We may need to practice sensitivity analysis, that is, to fit with and without this outlier and then compare the results.

2. Are the presence of *security guards* (`SEC_FT18` and `SEC_PT18`)  associated with reductions in crime (`INCID18`) and gun violence (`DISFIRE18`)? Interpret the effects clearly in language that a non-statistician could understand. 

We adopt two strategies. One is to code security guards as dichotomous variable (1 = Presence of security guards, 0 = Absence). In this way, we are more interested in investigating whether crime number is associated with the presence of security guards, but we do not care about the exact number of the security guards. The advantage of doing in this way is that less assumptions need to be made. The drawback is also self-evident -- we can only know if presence of security guards is associated with crime number, but we can't examine, say, if larger number of security guards is associated with bigger reduction in crime number.

Another strategy is to use the original data, that is the number of security guards as the independent variable. In this way, we can investigate, say, how much crime reduced is associated with, say, 10 more security guards deployed. The drawback is that we have to make the linear assumption of covariates, that is, if 1 more security guard is associated with, say, 5 fewer cases, then 2 more security guards must be associated with 10 fewer cases (in a normal linear model), or, if 1 more security guard is associated with, say, crime cases reducing by 3%, then 2 more security guards must be associated with cases reducing by 6% (in a Poisson model). This is sometimes too strong an assumption to make.

Let's carry out both strategies. To do so, we first produce the variables for our regression. We first add `SEC_FT18` and `SEC_PT18` to a new variable `SEC18`, which represents the number of both full-time and part-time security guards. We then generate a dummy variable `SEC_DUM18`, which represents if the number of security guards is greater than or equal to zero. However, we should notice that, for the first strategy (using dummy variable), if there is no other covariates included, then whatever model we run will be in essence equivalent. It's all about calculating two means, one for each group. Thus, we only use the first strategy once (with the simplest linear model).

```{r hypothesis2}
data$SEC18 <- data$SEC_FT18 + data$SEC_PT18
data$SEC_DUM18 <- data$SEC18 > 0
```

Let's first focus on outcome `INCID18` (overall crime). It makes no harm to first assume a linear model with OLS. We will use the two strategies mentioned above respectively. We first use the original count data of security guards:

```{r}
inc.fit1.a <- glm(INCID18 ~ SEC18, data = data)
```

In order to deal with potential heteroscedasticity, we will always use heteroscedasticity-robust standard error for our coefficient estimates wherever possible in our analysis.

```{r}
coeftest(inc.fit1.a, vcov. = vcovHC(inc.fit1.a, type = "HC1"))
```

Using the original data, we see that 10 more security guards is associated with about 13 more crimes.

Then we use the dummy variable:

```{r}
inc.fit1.b <- glm(INCID18 ~ SEC_DUM18, data = data)
coeftest(inc.fit1.b, vcov. = vcovHC(inc.fit1.b, type = "HC1"))
```

Using the dummy variable, we see that for schools without the presence of security guards, the expected number of crime cases is 13.2219, and for schools with security guards, the expected number of crime cases is $13.2219+19.5751=32.797$. The difference is 19.5751.

Then let's use Poisson model.

```{r}
inc.fit2 <- glm(INCID18 ~ SEC18, family = poisson, data = data)
coeftest(inc.fit2, vcov. = vcovHC(inc.fit2, type = "HC1"))
```

We see that 1 more security guard is associated with an increase of 2.4% of the crime.

To relax the assumption, we can also run a dispersed Poisson model and a negative binomial model respectively.

```{r}
inc.fit3 <- glm(INCID18 ~ SEC18, family = quasipoisson, data = data)
coeftest(inc.fit3, vcov. = vcovHC(inc.fit3, type = "HC1"))
inc.fit4 <- glm(INCID18 ~ SEC18, family = negative.binomial(1), data = data)
coeftest(inc.fit4, vcov. = vcovHC(inc.fit4, type = "HC1"))
```

The results are harder to interpret for these models, but we can see that more security guards is associated with more crime cases. 

Now let's focus on outcome `DISFIRE18`. We just repeat the procedures.

```{r}
fire.fit1.a <- glm(DISFIRE18 ~ SEC18, data = data)
coeftest(fire.fit1.a, vcov. = vcovHC(fire.fit1.a, type = "HC1"))
fire.fit1.b <- glm(DISFIRE18 ~ SEC_DUM18, data = data)
coeftest(fire.fit1.b, vcov. = vcovHC(fire.fit1.b, type = "HC1"))
fire.fit2 <- glm(DISFIRE18 ~ SEC18, family = poisson, data = data)
coeftest(fire.fit2, vcov. = vcovHC(fire.fit2, type = "HC1"))
fire.fit3 <- glm(DISFIRE18 ~ SEC18, family = quasipoisson, data = data)
coeftest(fire.fit3, vcov. = vcovHC(fire.fit3, type = "HC1"))
fire.fit4 <- glm(DISFIRE18 ~ SEC18, family = negative.binomial(1), data = data)
coeftest(fire.fit4, vcov. = vcovHC(fire.fit4, type = "HC1"))
```

Notice that, one outcome is 81 which is far greater than other observations. We thus practice sensitivity analysis, that is, to fit without this outlier and compare the results.

```{r}
fire.fit1.a.sens <- glm(DISFIRE18 ~ SEC18, data = data[data$DISFIRE18 != 81, ])
coeftest(fire.fit1.a.sens, vcov. = vcovHC(fire.fit1.a.sens, type = "HC1"))
fire.fit1.b.sens <- glm(DISFIRE18 ~ SEC_DUM18, data = data[data$DISFIRE18 != 81, ])
coeftest(fire.fit1.b.sens, vcov. = vcovHC(fire.fit1.b.sens, type = "HC1"))
fire.fit2.sens <- glm(DISFIRE18 ~ SEC18, family = poisson, data = data[data$DISFIRE18 != 81, ])
coeftest(fire.fit2.sens, vcov. = vcovHC(fire.fit2.sens, type = "HC1"))
fire.fit3.sens <- glm(DISFIRE18 ~ SEC18, family = quasipoisson, data = data[data$DISFIRE18 != 81, ])
coeftest(fire.fit3.sens, vcov. = vcovHC(fire.fit3.sens, type = "HC1"))
fire.fit4.sens <- glm(DISFIRE18 ~ SEC18, family = negative.binomial(1), data = data[data$DISFIRE18 != 81, ])
coeftest(fire.fit4.sens, vcov. = vcovHC(fire.fit4.sens, type = "HC1"))
```

From both models with and without the outlier, the coefficient of `SEC18` is always positive, although there is moderate change in the exact value.

We also notice that there is a large number of 0s in variable `DISPLAY18`. Thus we consider run a zero-inflated poisson regression model (with and without outlier). 

```{r}
fire.fit.zip <- zeroinfl(DISFIRE18 ~ SEC18, data = data)
summary(fire.fit.zip)
fire.fit.zip.sens <- zeroinfl(DISFIRE18 ~ SEC18, data = data[data$DISFIRE18 != 81, ])
summary(fire.fit.zip.sens)
```

Notice that using data with and without the outlier yields very different results. The sign of the coefficient of `SEC18` even changes! 

We may actually want to contact that school to see if this is a recording error or not beforehand. If so, we can simply remove or correct this observation. If not, we may not easily get rid of this observation, and thus sensitivity analysis results should better be reported.

Again, just like the number of overall incidents, more gun incidents is associated with a larger number of security guards. That is a bit surprising, huh? Generally we would think that increasing the number of security guards will reduce crime. However, if a school has a higher crime, then it is more likely to hire more security guards, isn't it? This is a kind of reversed causation. Things may get even trickier when we want to estimate an causal effect. We will discuss that in (4).

3. To what extent do these effects differ in urban schools versus non-urban schools?

In order to investigate the effects of different types of areas, we can include interaction term between `FR_URBAN` and `SEC18`. To simplify the problem a bit, we only run linear model and poisson model (with sensitivity analysis for outcome `DISFIRE18`).

```{r hypothesis3}
inc.fit5 <- glm(INCID18 ~ SEC18 * FR_URBAN, family = poisson, data = data)
coeftest(inc.fit5, vcov. = vcovHC(inc.fit5, type = "HC1"))
fire.fit5 <- glm(DISFIRE18 ~ SEC18 * FR_URBAN, family = poisson, data = data)
coeftest(fire.fit5, vcov. = vcovHC(fire.fit5, type = "HC1"))
fire.fit5.sens <- glm(DISFIRE18 ~ SEC18 * FR_URBAN, family = poisson, data = data[data$DISFIRE18 != 81, ])
coeftest(fire.fit5.sens, vcov. = vcovHC(fire.fit5.sens, type = "HC1"))
inc.fit6 <- glm(INCID18 ~ SEC18 * FR_URBAN, family = poisson, data = data)
coeftest(inc.fit6, vcov. = vcovHC(inc.fit6, type = "HC1"))
fire.fit6 <- glm(DISFIRE18 ~ SEC18 * FR_URBAN, family = poisson, data = data)
coeftest(fire.fit6, vcov. = vcovHC(fire.fit6, type = "HC1"))
fire.fit6.sens <- glm(DISFIRE18 ~ SEC18 * FR_URBAN, family = poisson, data = data[data$DISFIRE18 != 81, ])
coeftest(fire.fit6.sens, vcov. = vcovHC(fire.fit6.sens, type = "HC1"))
```

From both models, we see that there is no significant difference of effects between urban and non-urban areas.

4.  Do your analyses suggest that policymakers are correct that security guards reduce crime and gun violence? If so, explain why. If not, conduct additional analyses (using regression) that allow you to evaluate their claim and interpret your results. 

From the results in (2), we see that more security guards is associated with more crimes. However, **association is not causation**. In order to estimate a causal effect, it takes much bigger efforts. For what we have in our data, the only thing we can do is to include as many reasonable covariates as possible to reduce omitted variable bias. This of course can not guarantee a perfect estimation of the causal effect, but can reduce as much bias as possible. For example, let's include variables `FR_LVEL`, `FR_URBAN`, and `FR_SIZE` as covariates, and use poisson regression.

```{r hypothesis4}
inc.fit.c <- glm(INCID18 ~ SEC18 + FR_LVEL + FR_URBAN + FR_SIZE, family = poisson, data = data)
coeftest(inc.fit.c, vcov. = vcovHC(inc.fit.c, type = "HC1"))
fire.fit.c <- glm(DISFIRE18 ~ SEC18 + FR_LVEL + FR_URBAN + FR_SIZE, family = poisson, data = data)
coeftest(fire.fit.c, vcov. = vcovHC(fire.fit.c, type = "HC1"))
fire.fit.c.sens <- glm(DISFIRE18 ~ SEC18 + FR_LVEL + FR_URBAN + FR_SIZE, family = poisson, data = data[data$DISFIRE18 != 81, ])
coeftest(fire.fit.c.sens, vcov. = vcovHC(fire.fit.c.sens, type = "HC1"))
```

We see that our result shows that increasing security guards has no significant impact on gun violence, and even increases total crimes! That is against common sense. I bet this is still far from being the desired causal effect estimate. But we can not really do much. (I tried a few more models, and also different sets of covariates, but the results were not satisfying either.)

If we really want to get a causal estimate for this problem, two approaches come to my mind. One is to use instrumental variable design. Since there is reversed causality between number of security guards and crimes, only adjusting for omitted variable bias is not enough. We may want to find an instrument for the independent variable (which of course is not an easy task). Another thing is to use panel data rather than cross-sectional data. And we may probably use one-year lagged outcome to do the regression. These methods may better facilitate us to get a casual effect estimate. But anyway, if we have enough resources to perform an RCT, it will always be preferred.


# Part II. Predicting Crime

Other researchers and policymakers would like to develop a model to predict crime (`INCID18`) based upon observable school characteristics. Their idea is that they could first predict schools that have a lot of crime and then put in place interventions that could reduce such crime. 

For this part, perform the following tasks. 

1. For your first model, use variables `C0532`, `C0534`, `C0536`, `C0538`, `C0560`, `C0562`, `C0568`, `FR_LVEL`, `FR_URBAN`, and `FR_SIZE` as predictor variables. (In addition to Appendix B, you can find more detailed explanation for the variables `C0532` to `C0568` on pages 80-81 of the code book, and the three variables `FR_LVEL`, `FR_URBAN`, and `FR_SIZE` on page 172). Perform diagnostic analysis and draw your conclusion. Is there any further action you would like to do?

In order to do prediction, we first split the data as training set (50%) and test set (50%). Throughout our analysis in terms of prediction, we will use MSE (mean squared error) as an index of 'good' or 'bad' prediction model.

Let's first fit a linear model with only main effects of these predictors.

```{r predict1}
test.mse <- numeric()
set.seed(2022)
train <- sample(c(T, F), nrow(data), replace = T)
test <- !train
pred.fit.1 <- glm(INCID18 ~ C0532 + C0534 + C0536 + C0538 + as.factor(C0560) + as.factor(C0562) + C0568 + as.factor(FR_LVEL) + as.factor(FR_URBAN) + as.factor(FR_SIZE), data = data[train, ])
(test.mse[1] <- mean((pull(data[test, "INCID18"]) - predict(pred.fit.1, newdata = data[test,]))^2))
```

The MSE for linear model is `r test.mse[1]`.

We can also try fit a poisson model with only main effects of these predictors.

```{r}
pred.fit.2 <- glm(INCID18 ~ C0532 + C0534 + C0536 + C0538 + as.factor(C0560) + as.factor(C0562) + C0568 + as.factor(FR_LVEL) + as.factor(FR_URBAN) + as.factor(FR_SIZE), family = poisson, data = data[train, ])
(test.mse[2] <- mean((pull(data[test, "INCID18"]) - predict(pred.fit.2, newdata = data[test,]))^2))
```

The MSE for poisson model is `r test.mse[2]`. We can see that it is much bigger than poisson model. We thus decide to use linear model for the following analysis.


2.  Develop and implement an approach to build the best model possible that predicts the total number of crimes (incidents, `INCID18`). In addition to the variables mentioned in the previous problem, what other variables would you like to consider and why? What is your final model and why do you think it is the best?  Be sure to clearly explain your approach in language a non-statistician could understand.

We can try adding more terms into the regression, say, polynomials, natural splines, and so on. Let's first try polynomial with degrees 2-5. Notice that, `C0532`, `C0534`, `C0536`, `C0538` and `C0568` are continuous variables. And all others are categorical variables.

```{r predict2}
for(j in 2:5) {
  pred.fit <- glm(INCID18 ~ poly(C0532, j) + poly(C0534, j) + poly(C0536, j) + poly(C0538, j) +
                      as.factor(C0560) + as.factor(C0562) + poly(C0568, j) + as.factor(FR_LVEL) + as.factor(FR_URBAN) + as.factor(FR_SIZE), data = data[train, ])
  test.mse[j + 1] <- mean((pull(data[test, "INCID18"]) - predict(pred.fit, newdata =
                                                                   data[test,]))^2)
}
test.mse[3:6]
```

Notice that MSE for these models is not much different from the model with only main effects. We may also try natural spline with degree of freedom 3-6.

```{r}
for(j in 3:6) {
  pred.fit <- glm(INCID18 ~ ns(C0532, j) + ns(C0534, j) + ns(C0536, j) + ns(C0538, j) +
                      as.factor(C0560) + as.factor(C0562) + ns(C0568, j) + as.factor(FR_LVEL) + as.factor(FR_URBAN) + as.factor(FR_SIZE), data = data[train, ])
  test.mse[j + 4] <- mean((pull(data[test, "INCID18"]) - predict(pred.fit, newdata =
                                                                   data[test,]))^2)
}
test.mse[7:10]
```

Again, the results are not much different. What about also considering the interaction effects between these variables?

```{r}
pred.fit.3 <- glm(INCID18 ~ (C0532 + C0534 + C0536 + C0538 + as.factor(C0560) + as.factor(C0562)+ C0568 + as.factor(FR_LVEL) + as.factor(FR_URBAN) + as.factor(FR_SIZE))^2, data = data[train, ])
(test.mse[1] <- mean((pull(data[test, "INCID18"]) - predict(pred.fit.3, newdata = data[test,]))^2))
```

Which is again not much different. This may suggest, if we only use **these** variables as predictors, then only including main effects is enough, adding more non-linear terms will not improve the prediction by much.

We may also want to run Lasso regression, to see if any of these variables is not useful for prediction. The $\lambda$ value is selected by ten-fold cross validation.

```{r}
train.mat <- model.matrix(INCID18 ~ C0532 + C0534 + C0536 + C0538 + as.factor(C0560) + as.factor(C0562) + C0568 + as.factor(FR_LVEL) + as.factor(FR_URBAN) + as.factor(FR_SIZE), data = data[train, ])[, -1]
test.mat <- model.matrix(INCID18 ~ C0532 + C0534 + C0536 + C0538 + as.factor(C0560) + as.factor(C0562) + C0568 + as.factor(FR_LVEL) + as.factor(FR_URBAN) + as.factor(FR_SIZE), data = data[test, ])[, -1]
cv.lasso <- cv.glmnet(train.mat, pull(data[train, "INCID18"]), alpha = 1)
bestlam <- cv.lasso$lambda.min
lasso <- glmnet(test.mat, pull(data[test, "INCID18"]), alpha = 1)
predict(lasso, type = "coefficients", s = bestlam)
lasso.pred <- predict(lasso, newx = test.mat, s = bestlam)
(test.mse[11] <- mean((pull(data[test, "INCID18"]) - lasso.pred)^2))
```

We see that all the predictors are included. The MSE is `r test.mse[11]`, which slightly improves compared with the non-regularised regression.

But if we want to improve the results more, we have to jump out of these variables, and try other sets of predictors. We try to include all the non-composite variables (or variables directly from questionnaire), and then use Lasso regression to do variable selection.

```{r}
formula <- reformulate(names(data)[2:171], response = "INCID18")
train.mat <- model.matrix(formula, data = data[train, ])[, -1]
test.mat <- model.matrix(formula, data = data[test, ])[, -1]
cv.lasso <- cv.glmnet(train.mat, pull(data[train, "INCID18"]), alpha = 1)
bestlam <- cv.lasso$lambda.min
lasso <- glmnet(test.mat, pull(data[test, "INCID18"]), alpha = 1)
lasso.pred <- predict(lasso, newx = test.mat, s = bestlam)
(test.mse[12] <- mean((pull(data[test, "INCID18"]) - lasso.pred)^2))
```

By checking the coefficients (results are omitted), we see that only a few variables are kept. And also the MSE is largely reduced to `r test.mse[12]`.

Thus, we claim that, using lasso regression (with all the variables from questionnaire included) is a decent way to make predictions. The lasso regression itself can perform variable selection, which makes the model not too complex. And now that we decide to use lasso regression as our final model, then the final step is simply to fit the whole dataset to the model. We can then use this model for future predictions.