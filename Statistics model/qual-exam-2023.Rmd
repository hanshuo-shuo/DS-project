---
title: "Applied Statistics Qualifying Exam 2023"

output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
#library(readr)
#library(pscl)
library(mgcv)
library(tidyverse)
library(ggthemes)
library(pscl)
library(MASS)
library(lmtest)
library(sandwich)
library(boot)
library(glmnet)
library(splines)
data <- read.csv("vh_data15.csv")
names(data)
```

# An Overview of the Problem

As a result of public health campaigns, over 70% of individuals in the [United States](https://usafacts.org/visualizations/covid-vaccine-tracker-states/) have been fully vaccinated against COVID-19. Vaccination rates are particularly high for those ages 50 and over. Yet many remain unvaccinated - leading to questions regarding both *why* they are refusing vaccination and how to encourage them to *become* vaccinated. 

## The Data
[Sagir, Mewhirter, and Sanders (2022)](https://www.sciencedirect.com/science/article/pii/S0264410X22001347#s0085) conducted a Qualtrics survey in August 2020 and a followup in March 2022. The final survey includes 3,353 respondents. Each were asked a variety of questions regarding their vaccination status, any hesitancy, their trust in science and vaccines, and other information about themselves and their contexts. They used this information to create a predictive model to help public health researchers better understand vaccine hesitancy.

All of the information that you need to understand this data is provided. This includes:

 * `vh_data15.csv` : The data
 * `Sagir Mewhirter Sanders 2022.pdf` : The paper and codebook

## This Exam 

The purpose of this exam is to test your ability to put to use all that you have learned in STAT 350, 353, and 415 in the context of real data, with a real question. This involves combining your understanding of regression and machine learning concepts and theory with the implementation of these in code and clear interpretation to a lay audience. Be sure to convey what the results tell you, what assumptions they require, and any limitations in your results. 

For this exam, we will focus in particular on one outcome:

  - `Vaccine_Trust_Index` : an index of the degree to which a respondent trusts vaccines
  
**Finally, a strong exam is one that is judicious in what is presented (you can put materials in an Appendix), that explains the decisions and assumptions that were made and why, that explains the how the results should be interpreted, and that is clear in any limitations.**


## Submission of Report

*  Please complete Part I and Part II together and include your results using one Rmarkdown file. Please submit the .Rmd file and  the generated html or pdf file. 

* For Part III, please use python and include your results in an .ipynb file.

*  Please include your conclusion (i.e., your answer to question 9) in both the .Rmd file and the .ipynb file.



# Part I. Testing Hypotheses

For this part, answer the following questions:

1. What type of regression model will you use for `Vaccine_Trust_Index` (for example, least squares regression)? Explain your choice. 


```{r hypothesis1}
library(ggplot2)
ggplot(data, aes(x=Vaccine_Trust_Index)) + 
  geom_histogram(aes(y=after_stat(density)), fill="yellow", color="blue", bins=25) +
  geom_density(alpha=.2, fill="pink") +
  labs(title="Distribution of outcome Vaccine_Trust_Index", x="Vaccine_Trust_Index", y="Density")
```

According to the distribution plot of this variable `Vaccine_Trust_Index`, it has range around `0.0-10.0` and it is a continuous response variable. It is a little right skewed with most respondents tend to have a high trust in vaccines. And there are three models that I might use, the first is `Least Square Regression` and the second is `Generalized Additive Models`, the third is `Random Forest`

The reason for choosing the `Least Square Regression` is that it's flexible and can be used with both continuous and categorical predictors. If assumptions are met, OLS is the best linear unbiased estimator. Although the distribution of the response variable is not normally distributed,  residuals can still be  normally distributed. 

The reason for choosing the `Generalized Additive Models`: If there are non-linear relationships between the dependent variable and the predictors, or if there are complex interactions among predictors, a Generalized Additive Model (GAM) might be more appropriate. GAMs allow for more flexibility in capturing non-linear trends and interactions.

The reason for choosing the `Random Forest`: There are a lot of variables in this data, and Random Forest can easily capture interactions between features. And it can also capture all non-linear relationships.

Given the context, all models have their merits. However, before finalizing the choice, it would be essential to further explore the data, especially the relationships between Vaccine_Trust_Index and its predictors.

2. Measurement of trust is saved in the variable `Vaccine_Trust_Index`. You suspect that the following variables are associated with this vaccine trust index: `Natural_Science_Literacy`, `Perceived_Risk`, `Perceived_Network_Risk`, `College_Degree`, `Age`, and `Male`.  Please perform an analysis to evaluate these and draw your conclusions. Be sure to interpret your findings.

```{r hypothesis2}
model <- lm(Vaccine_Trust_Index ~ Natural_Science_Literacy + Perceived_Risk + 
            Perceived_Network_Risk + College_Degree + Age + Male, data=data)
summary(model)
```

All the predictors in the model are statistically significant and play a role in predicting `Vaccine_Trust_Index`. Variables like `Natural_Science_Literacy`, `Perceived_Network_Risk`, `College_Degree`, `Age`, and `Male` positively correlate with the trust index, whereas `Perceived_Risk` has a negative correlation. And we can interpret the model like this: Natural_Science_Literacy: For every one-unit increase in Natural_Science_Literacy, the Vaccine_Trust_Index is expected to increase by approximately 0.93 units, holding all else constant. This is statistically significant at the 0.001 level.


```{r}
model_gam <- gam(Vaccine_Trust_Index ~ s(Natural_Science_Literacy,k=7) + s(Perceived_Risk) +
                 s(Perceived_Network_Risk) + College_Degree + s(Age) + Male, 
                 data=data)
summary(model_gam)
plot(model_gam, pages=1)
```

All the predictors in the model appear to be significant. The plot shows that `Age`,`Natural_Science_Literacy`,`Perceived_Risk` and `Perceived_Network_Risk` exhibit some non-linearity, which can be addressed through the use of a gam model.


From the summary of the gam, On average, having a college degree is associated with an increase of about 0.75601 units in the Vaccine_Trust_Index compared to not having a college degree, holding other factors constant. Being male is associated with an increase of about 0.41235 units in the Vaccine_Trust_Index compared to being female (assuming female is the reference category), holding other factors constant. And there are trend we can read from the Smooth Terms. As we can infer from the plot of the gam, Variables like `Natural_Science_Literacy`, `Perceived_Network_Risk`, `Age`, are positively correlated with the trust index, whereas `Perceived_Risk` has a negative correlation. And we can interpret the smooth term like this: s(Perceived_Risk): This is the non-linear effect of Perceived_Risk. It also is statistically significant, and its edf is around 2.489, indicating a non-linear relationship. When edf is 1, there exist no non-linear relation effect.

The results are different to interpret for these two models, but we can see that the following variables are associated with this vaccine trust index. And they share the same trend that variables like `Natural_Science_Literacy`, `Perceived_Network_Risk`, `College_Degree`, `Age`, and `Male` positively correlate with the trust index, whereas `Perceived_Risk` has a negative correlation.


3. To what extent do these effects differ across those that voted for Trump versus those that did not? Interpret your findings.

I will carry on this analysis on two models. 

- First, I will add the interaction term Trump into the linear model to do the testing. The inclusion of interaction terms with the Trump variable allows you to investigate whether the effect of predictors on the Vaccine_Trust_Index differs based on whether someone voted for Trump or not.

```{r}
model <- glm(Vaccine_Trust_Index ~ Natural_Science_Literacy*Trump + Perceived_Risk*Trump + 
            Perceived_Network_Risk*Trump + College_Degree*Trump + Age*Trump + Male*Trump, data=data)
coeftest(model, vcov. = vcovHC(model, type = "HC1"))
```
In summary, while all predictors have similar interaction patterns for both Trump and non-Trump voters, the magnitudes of the interactions differ. For example, Natural_Science_Literacy has a positive relationship with trust in vaccines, but this effect is diminished (but still positive) among both Trump and non-Trump voters. This implies that while the direction of the influence might be similar, the strength varies based on whether or not they voted for Trump.

- Then, I carry on the similar method on Gam model: 

```{r}
data_trump <- subset(data, Trump == 'Yes')
data_not_trump <- subset(data, Trump == 'No')

model_gam_trump <- gam(Vaccine_Trust_Index ~ s(Natural_Science_Literacy,k=5) + s(Perceived_Risk) +s(Perceived_Network_Risk) + College_Degree + s(Age) + Male, 
                 data=data_trump)

model_gam_not_trump <- gam(Vaccine_Trust_Index ~ s(Natural_Science_Literacy, k=5) + s(Perceived_Risk) +
                 s(Perceived_Network_Risk) + College_Degree + s(Age) + Male, 
                 data=data_not_trump)
summary(model_gam_trump)
plot(model_gam_trump, pages = 1)
```

```{r}
summary(model_gam_not_trump)
plot(model_gam_not_trump, pages=1)
```

1. **College_Degree**: Both Trump and non-Trump voters with a college degree have higher trust in vaccines, but the effect is stronger in the Trump voters group.
2. **Male**: Being male is positively associated with the Vaccine_Trust_Index for both groups, but the effect is more pronounced among Trump voters.
3. **Natural_Science_Literacy**: While the relationship is not significant among Trump voters, there's a significant non-linear relationship among non-Trump voters.
4. **Perceived_Risk**: Significant for both groups, indicating its importance in determining Vaccine_Trust_Index regardless of voting preference.
5. **Perceived_Network_Risk & Age**: Both these predictors show significant non-linear relationships with the Vaccine_Trust_Index in both groups.

Overall, both models show that while there are similarities in the predictors' significance between the two groups, there are differences in the magnitude and nature of relationships, especially for Natural_Science_Literacy.


# Part II. Prediction

For this part, answer the following questions. 

4. Please use all available variables that could be used to develop a model to predict vaccine trust (`Vaccine_Trust_Index`). Perform diagnostic analysis and evaluate whether your model is reasonable. Is there any further action you would like to do?

In order to do prediction, we first split the data as training set (80%) and test set (20%). Throughout our analysis in terms of prediction, we will use MSE (mean squared error) and AIC scores as an index of 'good' or 'bad' prediction model. The AIC is a measure that considers the goodness-of-fit of the model and the number of parameters used.

```{r predict1}
# Set seed for reproducibility
set.seed(123)
data <- na.omit(data)
# Determine the number of rows to sample (80% of total rows)
sample_size <- floor(0.8 * nrow(data))

# Randomly sample row indices for the training set
train_indices <- sample(seq_len(nrow(data)), size = sample_size)

# Create the training and testing datasets using the sampled indices
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
```

```{r, warning=F}
Base <- glm(Vaccine_Trust_Index ~ 1, data = train_data)
Full <- glm(Vaccine_Trust_Index ~ .,
               data = train_data)
predicted_values <- predict(Full, newdata = test_data, type = "response")
actual_values <- test_data$Vaccine_Trust_Index
mean((actual_values - predicted_values)^2)
```

To start with, I use all available variables that could be used to develop a model to predict vaccine trust. Compared to the model we built in part 1, this bigger model have higher R-adj scores. And a much lower AIC score. Then, I use the step wise method to do the variable selection and use the final model I get to perform diagnose. 

```{r}
final_model <- stepAIC(Base, scope = list(upper = Full, lower = Base), direction = "both", trace = FALSE)
summary(final_model)
par(mfrow=c(2,2))  # Set up a 2x2 plot grid
plot(final_model)
actual_values <- test_data$Vaccine_Trust_Index
mse <- mean((actual_values - predicted_values)^2)
print(mse)
```
As we can see from the four plots above, the Q-Q plot seems nice, the points roughly follow the straight diagonal line, it suggests the residuals are normally distributed. But we can see some pattern in Residuals vs fitted plot, it suggests that the relationship is not simply linear. And we can also see spread of residuals increasing then decreasing as fitted values increase, it shows that homoscedasticity exists. And we get a mse of 2.214493, which is slightly improved.

More actions to be taken: first, I might add interaction or Polynomial Terms into the model to capture this non-linearity. And I might also try to use other types of models.

5. Develop and implement an approach to build the best model possible that predicts vaccine trust. What is your final model and why is the best? Be sure to clearly explain your approach in language a non-statistician could understand.


- **Step 1**: As shown in the previous question, I have tried to use the **step wise** to do the model selection and variables selection. This is the part where we need to get close to the best model. 

- **Step 2**:Based on previous analysis, I add add **interaction or Polynomial Terms** to the model:

```{r}
model = glm(formula = Vaccine_Trust_Index ~ Vaccine_Hesitant + Trust_Science_Community + I(Trust_Science_Community^2)+ 
    Doctor_Comfort + Perceived_Network_Risk*Age + Perceived_Network_Risk*College_Degree + I(Perceived_Network_Risk^2) + Trust_Local + Natural_Science_Literacy +
    +Trust_Science_Apolitical + Male + Trust_Media + Age  +  Perceived_Risk * College_Degree +
    College_Degree + Pandemic_Impact_Network + Party_ID + Evangelical + 
    Condition_Immune + Trust_National + Condition_Asthma + Condition_Heart, 
    data = train_data)
predicted_values <- predict(model, newdata = test_data, type = "response")
actual_values <- test_data$Vaccine_Trust_Index
mean((actual_values - predicted_values)^2)
AIC(model)
```
The result shows that MSE on the test set is greatly improved. And it also has a much lower AIC score of 9132.02, indicating this model is not only a better fit compared to the simple linear one but also did a better job at predicting new data points. 

- **Step 3**: I use the other type of model that I used in part 1, which is **GAMs**. Because it can capture non-linear relationships more flexibly.

```{r}
final_model_gam <- gam(Vaccine_Trust_Index ~ Vaccine_Hesitant + s(Trust_Science_Community) + s(Doctor_Comfort) + s(Natural_Science_Literacy,k=7) + s(Perceived_Network_Risk) + s(Perceived_Risk) +s(Trust_Local) + s(Perceived_Network_Risk) + College_Degree + s(Age) + Male + s(Trust_Science_Apolitical) + Trust_Media + s(Perceived_Risk) + Condition_Immune + s(Pandemic_Impact)  + Evangelical, data=train_data)
summary(final_model_gam)
AIC(final_model_gam)
```

```{r}
predicted_values <- predict(final_model_gam, newdata = test_data, type = "response")
plot(predicted_values, test_data$Vaccine_Trust_Index, main="Fitted vs. Predicted Values", 
     xlab="Real Values", ylab="Predicted Values", pch=16, col="blue")
abline(a=0, b=1, col="red", lwd=2)  
```

```{r}
actual_values <- test_data$Vaccine_Trust_Index
mse <- mean((actual_values - predicted_values)^2)
print(mse)
par(mfrow=c(2,2))
gam.check(final_model_gam)
```

After fitting the model, both the MSE and AIC score are slightly improved. And we can also see from the diagnose plots that the residuals are normally distributed and residuals vs prediction has less patterns. Indicating that this model GAMs is able to capture more information than previous linear model and polynomial models. But there might exist more comnplex interaction effect, so I want to do one more technique, which is RF.

- **Step 4**:in the end I want to use a ML technique to get a even better result, I try to use **random forest** here:

```{r predict2}
library(randomForest)
rf_model <- randomForest(Vaccine_Trust_Index ~ ., data=train_data)
```


```{r}
predicted_values <- predict(rf_model, newdata=test_data)
plot(predicted_values, test_data$Vaccine_Trust_Index, main="Fitted vs. Predicted Values", 
     xlab="Real Values", ylab="Predicted Values", pch=16, col="blue")
abline(a=0, b=1, col="red", lwd=2)  
actual_values <- test_data$Vaccine_Trust_Index
mse <- mean((actual_values - predicted_values)^2)
print(mse)
```

As shown by MSE on the test set, it has a much lower MSE than previous all models. Showing that it achieves the highest accuracy in predicting new data points. This means that the ML model might be the best in predicting this variable. If you are trying to prioritize understanding and interpreting the nature of relationships (especially in a smooth and possibly non-linear way), a GAM might be the better choice. On the other hand, A Random Forest is an ensemble of decision trees, making it more like a black box. So its hard to tell which one is the best, but they all do a decant predictive job here.

# Part III. Clustering

6.  Using a clustering algorithm such as K-Means or DBScan, perform a clustering analysis of the dataset. For this analysis, please make sure you have removed the outcome variables `Vaccine_Trust_Index` and `Vaccine_Hesitant`. For your clustering analysis, note that the dataset has both categorical variables and continuous variables. How do you handle this while clustering? How many clusters are best and why?

```{r cluster1}

```


7.  We want to understand what features the algorithm is selecting on in order to assign individuals into clusters. Please use LIME or a similar method to analyze the relative importance of each feature for cluster assignment. Interpret your findings.

```{r cluster2}

```


8.  Finally, we are interested in the association between these clusters and the outcome variable `Vaccine_Trust_Index`. Please try to perform a simple case of linear regression with an input variable of cluster index and the outcome variable of `Vaccine_Trust_Index`. Compare this model to your best predictive model in Part II. Which do you prefer and why?

```{r cluster3}

```


# Conclusion

9.  Putting together what you have learned in this exam and the findings from the Sanger et. al study, what are your conclusions? How could this data and analysis be used to guide health care policy and practice? Be sure to include any limitations.

- **The importance of two predictive tasks**: The paper has the conclusion that Vaccine Hesitancy Is Predictable with decent accuracy. And my predictive model in part 2 can also achieve a high accuracy in predicting the more complex outcome Vaccine_Trust_Index. And this is important, because understanding the predictors of vaccine hesitancy can help in future health crises. It is important to predict the Vaccine Trust Index because it is a significant predictor of COVID-19 vaccine hesitancy. The Vaccine Trust Index measures the extent to which individuals trust the safety and efficacy of the COVID-19 vaccine, as well as the information provided to the public about the vaccine. The higher the Vaccine Trust Index score, the more likely an individual is to accept the vaccine. By predicting an individual's Vaccine Trust Index score, public health officials and policymakers can better understand which individuals are more likely to be vaccine hesitant and design targeted interventions to increase vaccine acceptance. 

- **Some common factors are important in all three tasks**, like classification task in the paper, regression task in part 1 and 2, and the clustering task in part 3, such as as comfort with doctors, perceptions of risk, and age. It is to be noted that Trust is important in all three tasks, given that `Natural_Science_Literacy`, `Trust_Science_Community`, `Trust_Science_Politicians`, `Trust_Local` and `Trust_State` are all important in three models tasks. So public health campaigns should prioritize building and maintaining this trust. 

- **Machine Learning's Role**: Given the size of the dataset and the complexity of the prediction task, employing advanced machine learning techniques might yield better predictive performance. Techniques like Random Forests or even Neural Networks could be explored. And in part 2, I used RF to find out it offer improvements in prediction.

- **Model Limitations**: In part 2, I have 2 final models, as for the ploynomial model and the gam model, there still exist some patterns in the Residuals vs. Fitted plot suggest there might be additional variables or interactions that the model hasn't captured. But these models are easier to interpret. As for the RF model in part 2, it has better performance in predicting tasks, but can be rather difficult to interpret the results. And in the paper, the author also listed some limitations: 1: the model better classifies vaccine acceptant individuals (97%) relative to vaccine hesitant individuals (72%). 2: the study relied on a quota-based online convenience sample and the presence of non-random attrition presents complications for the generalizability of the findings. 3: the model demonstrates how strongly the included variables contribute to the predictive capacity of the model, but the relationship is not necessarily causal. 4: the study included a wide array of covariates, but there likely exist a number of unmodeled features. 